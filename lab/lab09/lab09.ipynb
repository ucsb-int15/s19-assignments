{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab09.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.469577Z",
     "start_time": "2018-04-02T16:07:15.663122Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this lab we will be covering a very popular classification technique known as **logistic regression**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data\n",
    "\n",
    "For this lecture we will use the Wisconsin Breast Cancer Dataset which we can obtain from [scikit learn](http://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-database).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.590723Z",
     "start_time": "2018-04-02T16:07:17.472304Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "data_dict = sklearn.datasets.load_breast_cancer()\n",
    "data = pd.DataFrame(data_dict['data'], columns=data_dict['feature_names'])\n",
    "# Target data_dict['target'] = 0 is malignant 1 is benign\n",
    "data['malignant'] = (data_dict['target'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.599437Z",
     "start_time": "2018-04-02T16:07:17.593220Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.755067Z",
     "start_time": "2018-04-02T16:07:17.601012Z"
    }
   },
   "outputs": [],
   "source": [
    "points = go.Scatter(x=data['mean radius'], y = 1.*data['malignant'], mode=\"markers\")\n",
    "layout = dict(xaxis=dict(title=\"Mean Radius\"),yaxis=dict(title=\"Malignant\"))\n",
    "py.iplot(go.Figure(data=[points], layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a clear example of over-plotting.  We can improve the above plot by jittering the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.773256Z",
     "start_time": "2018-04-02T16:07:17.757563Z"
    }
   },
   "outputs": [],
   "source": [
    "jitter_y = data['malignant'] + 0.1 * np.random.rand(data['malignant'].size) -0.05\n",
    "points = go.Scatter(x=data['mean radius'], y = jitter_y, \n",
    "                    mode=\"markers\", \n",
    "                    marker=dict(opacity=0.5))\n",
    "py.iplot(go.Figure(data=[points], layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a better way to visualize the data is using stacked histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.896849Z",
     "start_time": "2018-04-02T16:07:17.775139Z"
    }
   },
   "outputs": [],
   "source": [
    "py.iplot(ff.create_distplot(\n",
    "    [data.loc[~data['malignant'], 'mean radius'],\n",
    "     data.loc[data['malignant'], 'mean radius']], \n",
    "    group_labels=[\"Benign\",\"Malignant\"],\n",
    "    bin_size=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Prediction rule\n",
    "Looking at the above histograms could you describe a rule to predict whether or a cell is malignant?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Regression\n",
    "\n",
    "**Goal:** We would like to predict whether the tumor is malignant from the size of the tumor. We will be using least square regression to build a classifier that can achieve the objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " \n",
    "\n",
    "## Part 1a- Preparing the data Train-Test Split\n",
    "Always split your data into training and test groups. The model learns from the training examples and then we test our model on the test set. In this example we will first split the data using the train_test_split from sklearn. Keep 75% of the data for training and the remaining 25% for testing.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.924717Z",
     "start_time": "2018-04-02T16:07:17.899036Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_tr, data_te =...\n",
    "...\n",
    "print(\"Training Data Size: \", len(data_tr))\n",
    "print(\"Test Data Size: \", len(data_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1b- Setting labels and Values\n",
    "Now let us visualize the data. \n",
    "We will define $X$ and $Y$ as variables containing the training features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:17.931358Z",
     "start_time": "2018-04-02T16:07:17.926492Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data_tr.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The row mean radius gives us the radius of each tumor. You will now be selecting the values from the mean radius and storing it in the data variable X. Similary \"malignant\" column tells us whether the tumor is malignant or not. In order to prepare the training labels you will store these values in the float format where 0 stands for false and 1 stands for true. This will be stored in variable Y.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=...\n",
    "Y=...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part 2a- Fitting a least square regression module \n",
    "Once we are done with the basics of data modelling you can fit a least square regression module on the data. Follow the given instructions:\n",
    "1. Use the `LinearRegression()` function to create a model for least square linear regression\n",
    "2. Use the `fit()` function to fit the data $(X,Y)$\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.006048Z",
     "start_time": "2018-04-02T16:07:17.933377Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "# Call the linear regression model\n",
    "least_squares_model = ...\n",
    "# Now use the fit function \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is our fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.026129Z",
     "start_time": "2018-04-02T16:07:18.007888Z"
    }
   },
   "outputs": [],
   "source": [
    "jitter_y = Y + 0.1*np.random.rand(len(Y)) - 0.05\n",
    "points = go.Scatter(name=\"Jittered Data\", \n",
    "                    x=np.squeeze(X), y = jitter_y, \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5))\n",
    "X_plt = np.linspace(np.min(X), np.max(X), 10)\n",
    "model_line = go.Scatter(name=\"Least Squares\",\n",
    "    x=X_plt, y=least_squares_model.predict(X_plt[:,np.newaxis]), \n",
    "    mode=\"lines\", line=dict(color=\"orange\"))\n",
    "py.iplot([points, model_line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Questions:\n",
    "1. Are we happy with the fit?\n",
    "2. What is the meaning of predictions that are neither 0 or 1?\n",
    "3. Could we use this to make a decision?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part 2b- What is the Root Mean Squared Error?\n",
    "Calcualte the mean squared error by using the mse module and predict function.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.032417Z",
     "start_time": "2018-04-02T16:07:18.028104Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "rmse=...\n",
    "...\n",
    "print(\"Training RMSE:\",rmse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  Part 3-Classification Error\n",
    "\n",
    "This is a classification problem, so we probably want to measure how often we predict the correct value.  This is sometimes called the zero-one loss (or error):\n",
    "\n",
    "$$ \\large\n",
    "\\textbf{ZeroOneLoss} = \\frac{1}{n} \\sum_{i=1}^n \\textbf{I}\\left[ y_i \\neq f_\\theta(x) \\right]\n",
    "$$\n",
    "\n",
    "However, to use the classification error we need to define a decision rule that maps $f_\\theta(x)$ to the $\\{0,1\\}$ classification values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Question 3a Simple Decision Rule\n",
    "\n",
    "Therefore, in order to solve the issue, we instituted the following simple decision rule:\n",
    "\n",
    "$$\\Large\n",
    "\\text{If } f_\\theta(x) > 0.5  \\text{ predict 1 (malignant) else predict 0 (benign).}\n",
    "$$\n",
    "\n",
    "This simple **decision rule** is deciding that a tumor is malignant if our model predicts a value above 0.5 (closer to 1 than zero).\n",
    "\n",
    "We will now be developing a classifier based on this simple rule. The output results are stored as boolean outcomes and are set to True for all values that are greater than 0.5 and False for all values that are less than 0.5.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_mal=...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3a\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.059302Z",
     "start_time": "2018-04-02T16:07:18.034361Z"
    }
   },
   "outputs": [],
   "source": [
    "jitter_y = Y + 0.1*np.random.rand(len(Y)) - 0.05\n",
    "ind_mal = least_squares_model.predict(X) > 0.5\n",
    "\n",
    "mal_points = go.Scatter(name=\"Classified as Malignant\", \n",
    "                    x=np.squeeze(X[ind_mal]), y = jitter_y[ind_mal], \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5, color=\"red\"))\n",
    "ben_points = go.Scatter(name=\"Classified as Benign\", \n",
    "                    x=np.squeeze(X[~ind_mal]), y = jitter_y[~ind_mal], \n",
    "                    mode=\"markers\", marker=dict(opacity=0.5, color=\"blue\"))\n",
    "dec_boundary = (0.5 - least_squares_model.intercept_)/least_squares_model.coef_[0]\n",
    "dec_line = go.Scatter(name=\"Least Squares Decision Boundary\", \n",
    "                      x = [dec_boundary,dec_boundary], y=[-0.5,1.5], mode=\"lines\",\n",
    "                     line=dict(color=\"black\", dash=\"dot\"))\n",
    "py.iplot([mal_points, ben_points, model_line,dec_line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Compute `ZeroOneLoss`\n",
    "You will now be computing tht zero one loss and predicting the fraction of the data that is incorrect. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.067202Z",
     "start_time": "2018-04-02T16:07:18.061723Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "zerooneloss=...\n",
    "...\n",
    "print(\"Training Fraction incorrect:\", zerooneloss)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Questions** \n",
    "\n",
    "1. Are we happy with this error level?\n",
    "1. What error would we get if we just guessed the label?\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guessing the Majority Class\n",
    "\n",
    "This is the simplest baseline we could imagine and one you should always compare against.  Let's start by asking what is the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.072065Z",
     "start_time": "2018-04-02T16:07:18.069177Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Fraction of Malignant Samples:\", np.mean(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we guess the majority class **benign**, what accuracy would we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.078040Z",
     "start_time": "2018-04-02T16:07:18.074158Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can figure this out from the above number\n",
    "print(\"Guess Majority:\",  zero_one_loss(Y, np.zeros(len(Y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is standard example of a common problem in classification (and perhaps modern society): **class imbalance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# Part 4 Cross Validation of Zero-One Error\n",
    "\n",
    "You will now be performing one of the most popular techniques for evaluating a classification model. The techniques is known as cross-validation. Cross-validation refers to breaking the entire data-set into $n$ parts where the $n-1$ parts are used for training and one of the parts is used for validation. The cycle is repeated for each part. Finally, the overall error is calculated for each part.\n",
    "\n",
    "You will be performing a 3-fold cross validation in this section. Do the following\n",
    "1. Call the linear regression model and fit it on `tr_ind` for X and Y\n",
    "2. Predict the outcome of the model using `model.predict` for `te_ind` and store it in outcome\n",
    "3. Calculate the zero one loss for the predicted values\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.096792Z",
     "start_time": "2018-04-02T16:07:18.080117Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(3,shuffle=True, random_state=42)\n",
    "linreg_errors = []\n",
    "models = []\n",
    "\n",
    "for tr_ind, te_ind in kfold.split(X):\n",
    "    # Create a linear regression model and fit it with the training data and indices\n",
    "    model=...\n",
    "    ...\n",
    "    models.append(model)\n",
    "    # Predict the outcome on the test data\n",
    "    outcome = ...\n",
    "    \n",
    "    # Calculate the zero one loss for the predicted solution\n",
    "    zerooneloss = ...\n",
    "    \n",
    "    # Append the zerooneloss to linreg_errors variable\n",
    "    ...\n",
    "    \n",
    "print(\"Min Validation Error:   \", np.min(linreg_errors))\n",
    "print(\"Median Validation Error:\", np.median(linreg_errors))\n",
    "print(\"Max Validation Error:   \", np.max(linreg_errors))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize all the models and their decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.126257Z",
     "start_time": "2018-04-02T16:07:18.099160Z"
    }
   },
   "outputs": [],
   "source": [
    "dec_lines = [\n",
    "    go.Scatter(name=\"Decision Boundary\", \n",
    "               x = [(0.5 - m.intercept_)/m.coef_[0]]*2, \n",
    "               y=[-0.5,1.5], mode=\"lines\",\n",
    "               line=dict(dash=\"dot\"))\n",
    "    for m in models]\n",
    "\n",
    "X_plt = np.linspace(np.min(X), np.max(X), 10)\n",
    "model_lines = [\n",
    "    go.Scatter(name=\"Least Squares \" + str(zero_one_loss(Y, m.predict(X) > 0.5)),\n",
    "               x=X_plt, y=m.predict(np.array([X_plt]).T), \n",
    "               mode=\"lines\")\n",
    "    for m in models]\n",
    "py.iplot([points] + model_lines + dec_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Can we think of the line as a _\"probability\"_?\n",
    "\n",
    "\n",
    "Not really.  Probabilities are constrained between 0 and 1.   How could we learn a model that captures this probabilistic interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Could we just truncate the line?\n",
    "\n",
    "Maybe. \n",
    "\n",
    "We can define the probability as:\n",
    "\n",
    "$$ \\large\n",
    "p_i = \\min\\left(\\max \\left( x^T \\theta , 0 \\right), 1\\right)\n",
    "$$\n",
    "\n",
    "which would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.131948Z",
     "start_time": "2018-04-02T16:07:18.128385Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bound01(z):\n",
    "    u = np.where(z > 1, 1, z)\n",
    "    return np.where(u < 0, 0, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.155130Z",
     "start_time": "2018-04-02T16:07:18.134002Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plt = np.linspace(np.min(X), np.max(X), 100)\n",
    "p_line = go.Scatter(name=\"Truncated Least Squares\",\n",
    "    x=X_plt, y=bound01(least_squares_model.predict(np.array([X_plt]).T)), \n",
    "    mode=\"lines\", line=dict(color=\"green\", width=8))\n",
    "py.iplot([mal_points, ben_points, model_line, p_line, dec_line], filename=\"lr-06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, least squares regression seems pretty reasonable and we can \"force\" the predicted values to be bounded between 0 and 1.  \n",
    "\n",
    "\n",
    "**Can we interpret the truncated values as probabilities?** \n",
    "\n",
    "Perhaps, but it would depend on how the model is estimated (more on this soon).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# An Issue with Extreme Points \n",
    "\n",
    "It seems like large tumor sizes are indicative of malignant tumors.  Suppose we observed a very large malignant tumor that is 100mm in mean radius.  What would this do to our model?\n",
    "\n",
    "\n",
    "Let's add an extra data point and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:07:18.165906Z",
     "start_time": "2018-04-02T16:07:18.157445Z"
    }
   },
   "outputs": [],
   "source": [
    "X_ex = np.vstack([X, [100]])\n",
    "Y_ex = np.hstack([Y, 1.])\n",
    "least_squares_model_ex = linear_model.LinearRegression()\n",
    "least_squares_model_ex.fit(X_ex, Y_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:08:52.741027Z",
     "start_time": "2018-04-02T16:08:52.706346Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plt = np.linspace(np.min(X)-5, np.max(X)+5, 100)\n",
    "\n",
    "extreme_point = go.Scatter(\n",
    "    name=\"Extreme Point\", x=[100], y=[1], mode=\"markers\", \n",
    "    marker=dict(color=\"green\", size=10))\n",
    "model_line.line.color = \"gray\"\n",
    "model_line_ex = go.Scatter(name=\"New Least Squares\",\n",
    "    x=X_plt, y=least_squares_model_ex.predict(np.array([X_plt]).T), \n",
    "    mode=\"lines\", line=dict(color=\"orange\"))\n",
    "\n",
    "dec_line.line.color = \"gray\"\n",
    "\n",
    "dec_boundary_ex = (0.5 - least_squares_model_ex.intercept_)/least_squares_model_ex.coef_[0]\n",
    "dec_line_ex = go.Scatter(\n",
    "    name=\"Decision Boundary\", \n",
    "    x = [dec_boundary_ex, dec_boundary_ex], y=[-0.5,1.5], mode=\"lines\",\n",
    "    line=dict(color=\"black\", dash=\"dash\"))\n",
    "\n",
    "\n",
    "\n",
    "py.iplot([mal_points, ben_points,model_line, model_line_ex, dec_line, dec_line_ex, extreme_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the resulting RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T16:09:16.748183Z",
     "start_time": "2018-04-02T16:09:16.743636Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Before:\", \n",
    "      zero_one_loss(Y_ex, least_squares_model.predict(X_ex) > 0.5))\n",
    "print(\"After:\", \n",
    "      zero_one_loss(Y_ex, least_squares_model_ex.predict(X_ex) > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "source": [
    "Looking at the above results, explain what you observed.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 4 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('lab09.ipynb', 'lab09.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
