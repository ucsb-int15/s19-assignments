{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.options.display.max_rows = 7\n",
    "pd.options.display.max_columns = 8\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataTables, Indexes, Pandas, and Seaborn\n",
    "\n",
    "## Some useful (free) resources\n",
    "\n",
    "Introductory:\n",
    "\n",
    "* [Getting started with Python for research](https://github.com/TiesdeKok/LearnPythonforResearch), a gentle introduction to Python in data-intensive research.\n",
    "\n",
    "* [A Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/index.html), by Jake VanderPlas, another quick Python intro (with notebooks).\n",
    "\n",
    "Also,\n",
    "\n",
    "* [Data Camp](https://www.datacamp.com)\n",
    "\n",
    "* [Software Carpentry](https://software-carpentry.org/lessons)\n",
    "\n",
    "* [Beginner Python Programming Tutorials on YouTube (Socratica)](https://www.youtube.com/watch?v=bY6m6_IIN94&list=PLi01XoE8jYohWFPpC17Z-wWhPOSuh8Er-)\n",
    "\n",
    "Core Pandas/Data Science books:\n",
    "\n",
    "* [The Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/), by Jake VanderPlas.\n",
    "\n",
    "* [Python for Data Analysis, 2nd Edition](http://proquest.safaribooksonline.com/book/programming/python/9781491957653), by  Wes McKinney, creator of Pandas. [Companion Notebooks](https://github.com/wesm/pydata-book)\n",
    "\n",
    "* [Effective Pandas](https://github.com/TomAugspurger/effective-pandas), a book by Tom Augspurger, core Pandas developer.\n",
    "\n",
    "\n",
    "Complementary resources:\n",
    "\n",
    "* [An introduction to \"Data Science\"](https://github.com/stefanv/ds_intro), a collection of Notebooks by BIDS' [St√©fan Van der Walt](https://bids.berkeley.edu/people/st%C3%A9fan-van-der-walt).\n",
    "\n",
    "* [Effective Computation in Physics](http://proquest.safaribooksonline.com/book/physics/9781491901564), by Kathryn D. Huff; Anthony Scopatz. [Notebooks to accompany the book](https://github.com/physics-codes/seminar). Don't be fooled by the title, it's a great book on modern computational practices with very little that's physics-specific.\n",
    "\n",
    "* [Towards Data Science](https://towardsdatascience.com/), a large collection of articles for data science topics\n",
    "\n",
    "\n",
    "OK, let's load and configure some of our core libraries (as an aside, you can find a nice visual gallery of available matplotlib sytles [here](https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes are adapted from the [Principles and Techniques of Data Science](https://www.textbook.ds100.org/ch/03/pandas_intro.html) textbook.\n",
    "\n",
    "\n",
    "## Part 1: Getting Started\n",
    "\n",
    "We will work with the Baby Names dataset available from the [Social Security Data Page](https://www.ssa.gov/data/): https://www.ssa.gov/OACT/babynames/index.html. We will pose a question, break the question down into high-level steps, then translate each step into Python code using `pandas` DataFrames. We begin by importing `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Sex,Count,Year\r\n",
      "Mary,F,9217,1884\r\n",
      "Anna,F,3860,1884\r\n",
      "Emma,F,2587,1884\r\n",
      "Elizabeth,F,2549,1884\r\n",
      "Minnie,F,2243,1884\r\n",
      "Margaret,F,2142,1884\r\n",
      "Ida,F,1882,1884\r\n",
      "Clara,F,1852,1884\r\n",
      "Bertha,F,1789,1884\r\n"
     ]
    }
   ],
   "source": [
    "# Use the shell command `head` to preview the first 10 items in the CSV\n",
    "!head babynames.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read in the data using `pd.read_csv` ([docs](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891894"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby = pd.read_csv('babynames.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the code above to work, the `babynames.csv` file must be located in the same directory as this notebook. We can check what files are in the current folder by running the `ls` command-line tool (you can also omit the `!`, since it's one of the most-used commands; for more information, see [Chapter 1: IPython and Shell Commands](https://jakevdp.github.io/PythonDataScienceHandbook/01.05-ipython-and-shell-commands.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use `pandas` to read in data, we get a DataFrame. A DataFrame is a tabular data structure where each column is labeled (in this case 'Name', 'Sex', 'Count', 'Year') and each row is labeled (in this case 0, 1, 2, ..., 1891893).\n",
    "\n",
    "The labels of a DataFrame are called the *indexes* of the DataFrame and make many data manipulations easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes, Slicing, and Sorting\n",
    "\n",
    "Let's use `pandas` to answer the following question:\n",
    "\n",
    "**What were the five most popular baby names in 2016?**\n",
    "\n",
    "### Breaking the Problem Down\n",
    "\n",
    "We can decompose this question into the following simpler table manipulations:\n",
    "\n",
    "1. Slice out the rows for the year 2016.\n",
    "2. Sort the rows in descending order by Count.\n",
    "\n",
    "Now, we can express these steps in `pandas`.\n",
    "\n",
    "### Slicing using `.loc`\n",
    "\n",
    "To select subsets of a DataFrame, we use the `.loc` slicing syntax. The first argument is the label of the row and the second is the label of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.loc[0, 'Name'] # Row labeled 1, Column labeled 'Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To slice out multiple rows or columns, we can use `:`. Note that **`.loc` slicing is inclusive, unlike Python's slicing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows 1 through 5, columns Name through Count inclusive\n",
    "baby.loc[1:5, 'Name':'Count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slight tangent: exploring slicing, indexing and manipulation of DataFrames and Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will often want a single column from a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.loc[:, 'Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we select a single column, we get a `pandas` Series. A Series is like a one-dimensional NumPy array since we can perform arithmetic on all the elements at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.loc[:, 'Year'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select out specific columns, we can pass a list into the `.loc` slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a DataFrame again\n",
    "baby.loc[:, ['Name', 'Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns is common, so there's a shorthand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorthand for baby.loc[:, 'Name']\n",
    "baby['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorthand for baby.loc[:, ['Name', 'Count']]\n",
    "baby[['Name', 'Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, end of tangent.\n",
    "\n",
    "Let's get back to the original task.\n",
    "\n",
    "#### Slicing rows using a predicate\n",
    "\n",
    "To slice out the rows with year 2016, we will first create a Series containing `True` for each row we want to keep and `False` for each row we want to drop. This is simple because math and boolean operators on Series are applied to each element in the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of years\n",
    "baby['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare each year with 2016\n",
    "baby['Year'] == 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this Series of `True` and `False`, we can pass it into `.loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are slicing rows, so the boolean Series goes in the first\n",
    "# argument to .loc\n",
    "baby_2016 = baby.loc[baby['Year'] == 2016, :]\n",
    "baby_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Rows\n",
    "\n",
    "The next step is the sort the rows in descending order by 'Count'. We can use the `sort_values()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_2016 = baby_2016.sort_values('Count', ascending=False)\n",
    "sorted_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use `.iloc` to slice out the first five rows of the DataFrame. **`.iloc` works like `.loc` but takes in numerical indices instead of labels**. It **does not include the right endpoint** in its slices, like Python's list slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value in the zeroth row, zeroth column\n",
    "sorted_2016.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first five rows\n",
    "sorted_2016.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Conclusion\n",
    "\n",
    "We now have the five most popular baby names in 2016 and learned to express the following operations in `pandas`:\n",
    "\n",
    "| Operation | `pandas` |\n",
    "| --------- | -------  |\n",
    "| Read a CSV file | `pd.read_csv()` |\n",
    "| Slicing using labels or indices | `.loc` and `.iloc` |\n",
    "| Slicing rows using a predicate | Use a boolean-valued Series in `.loc` |\n",
    "| Sorting rows | `.sort_values()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Grouping and Pivoting\n",
    "\n",
    "In this section, we will answer the question:\n",
    "\n",
    "**What were the most popular male and female names in each year?**\n",
    "\n",
    "Here's the Baby Names dataset once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby = pd.read_csv('babynames.csv')\n",
    "baby.head()\n",
    "# the .head() method outputs the first five rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking the Problem Down\n",
    "\n",
    "We should first notice that the question in the previous section has similarities to this one; the question in the previous section restricts names to babies born in 2016 whereas this question asks for names in all years.\n",
    "\n",
    "We once again decompose this problem into simpler table manipulations.\n",
    "\n",
    "1. Group the `baby` DataFrame by 'Year' and 'Sex'.\n",
    "2. For each group, compute the most popular name.\n",
    "\n",
    "Recognizing which operation is needed for each problem is sometimes tricky. Usually, a convoluted series of steps will signal to you that there might be a simpler way to express what you want. If we didn't immediately recognize that we needed to group, for example, we might write steps like the following:\n",
    "\n",
    "1. Loop through each unique year.\n",
    "2. For each year, loop through each unique sex.\n",
    "3. For each unique year and sex, find the most common name.\n",
    "\n",
    "There is almost always a better alternative to looping over a `pandas` DataFrame. **In particular, looping over unique values of a DataFrame should usually be replaced with a group.**\n",
    "\n",
    "### Grouping\n",
    "\n",
    "To group in `pandas`. we use the `.groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.groupby('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.groupby()` returns a strange-looking `DataFrameGroupBy` object. We can call `.agg()` on this object with an aggregation function in order to get a familiar output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aggregation function takes in a series of values for each group\n",
    "# and outputs a single value\n",
    "def length(series):\n",
    "    return len(series)\n",
    "\n",
    "# Count up number of values for each year. This is equivalent to\n",
    "# counting the number of rows where each year appears.\n",
    "baby.groupby('Year').agg(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the `length` function simply calls the `len` function, so we can simplify the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.groupby('Year').agg(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation is applied to each column of the DataFrame, producing redundant information. We can restrict the output columns by slicing before grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_rows = baby[['Year', 'Count']].groupby('Year').agg(len)\n",
    "year_rows\n",
    "\n",
    "# A further shorthand to accomplish the same result:\n",
    "#\n",
    "# year_counts = baby[['Year', 'Count']].groupby('Year').count()\n",
    "#\n",
    "# pandas has shorthands for common aggregation functions, including\n",
    "# count, sum, and mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index of the resulting DataFrame now contains the unique years, so we can slice subsets of years using `.loc` as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every twentieth year starting at 1880\n",
    "year_rows.loc[1880:2016:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping on Multiple Columns\n",
    "\n",
    "We can group on multiple columns to get groups based on unique pairs of values. To do this, pass in a list of column labels into `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_counts = baby.groupby(['Year', 'Sex']).max()\n",
    "grouped_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above computes the total number of babies born for each year and sex. Let's now use grouping by muliple columns to compute the most popular names for each year and sex. Since the data are already sorted in descending order of Count for each year and sex, we can define an aggregation function that returns the first value in each series. (If the data weren't sorted, we can call `sort_values()` first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most popular name is simply the first one that appears in the series\n",
    "def most_popular(series):\n",
    "    return series.iloc[0]\n",
    "\n",
    "baby_pop = baby.groupby(['Year', 'Sex']).agg(most_popular)\n",
    "baby_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that grouping by multiple columns results in multiple labels for each row. This is called a \"multilevel index\" and is tricky to work with. The important thing to know is that **`.loc` takes in a tuple for the row index instead of a single value**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_pop.loc[(2000, 'M'), 'Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But `.iloc` behaves the same as usual since it uses indices instead of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_pop.iloc[10:15, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "**If you group by two columns, you can often use pivot to present your data in a more convenient format.** Using a pivot lets you use one set of grouped labels as the columns of the resulting table.\n",
    "\n",
    "To pivot, use the `pd.pivot_table()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(baby,\n",
    "               index='Year',         # Index for rows\n",
    "               columns='Sex',        # Columns\n",
    "               values='Name',        # Values in table\n",
    "               aggfunc=most_popular) # Aggregation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this result to the `baby_pop` table that we computed using `.groupby()`. We can see that the `Sex` index in `baby_pop` became the columns of the pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Conclusion\n",
    "\n",
    "We now have the most popular baby names for each sex and year in our dataset and learned to express the following operations in `pandas`:\n",
    "\n",
    "| Operation | `pandas` |\n",
    "| --------- | -------  |\n",
    "| Group | `df.groupby(label)` |\n",
    "| Group by multiple columns | `df.groupby([label1, label2])` |\n",
    "| Group and aggregate | `df.groupby(label).agg(func)` |\n",
    "| Pivot | `pd.pivot_table()` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
